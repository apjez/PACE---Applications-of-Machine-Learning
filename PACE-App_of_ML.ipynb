{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:24pt; text-decoration:underline; font-weight:bold; color:#003057; text-align:center\">\n",
    "    PACE - Applications of Machine Learning\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <a href = \"mailto: ajezghani3@gatech.edu\"><b>Aaron Jezghani, PhD</b></a> : <a href = \"https://pace.gatech.edu\" target = \"_blank\"><b>PACE, Georgia Tech</b></a> <br>\n",
    "    <a href = \"mailto: chris_blanton@ncsu.edu\"><b>Chris Blanton, PhD</b></a> : <a href = \"https://www.lib.ncsu.edu\" target= \"_blank\"><b>Research Consulting, NCSU</b></a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>Introduction</b></u></font>\n",
    "\n",
    "<br>\n",
    "<center><font size=4><i>[Machine Learning is a] field of study that gives computers the ability to learn without being explicitly programmed.</i> <br> --- Arthur Samuel, 1959</font></center>\n",
    "\n",
    "Machine learning has existed for decades; however, until recently, computing power and data storage were too limited to allow machines to solve many problems in the field effectively. Advances in speed and density have taken machine learning from an abstract idea to the forefront of scientific research across many domains, including:\n",
    "- Bioinformatics\n",
    "- Molecular dynamics\n",
    "- Astrophysics\n",
    "- Signal processing\n",
    "- Health data analytics\n",
    "- Finance and marketing\n",
    "- Urban planning\n",
    "- ...and many more\n",
    "\n",
    "The volume of data being generated and made available for research is rapidly increasing, and while the technology is constantly being reconsidered to keep up, the challenge of meaningfully utilizing it is becoming ever more present. Even if we ignore the challenges of human bias, the efficiency of humans in reviewing data remains \n",
    "\n",
    "<font size=4 color=B3A369><b>Spam Filters: The Traditional Way</b></font>\n",
    "\n",
    "1. We want to start by identifying some common features in spam emails; these could be:\n",
    "    - phrases (\"4U\", \"one simple trick\", \"aliens\", \"lottery\"), \n",
    "    - questionable domains (\"google.asdqwkjf92.ohno\", \"definitely-not-stealing-your-info.org\"),\n",
    "    - mismatches in sender's name/email (\"Mary Smith from aaron.aaron@itsascam.net\"),\n",
    "    - etc.\n",
    "2. We would write some rules to capture these bits\n",
    "    - You may have already done this for your school/work emails to sort by topic!\n",
    "3. We then execute the email rules to test their validity\n",
    "    - We need to identify correctness, including false positives (good emails mislabeled as spam) and false negatives (spam emails that were missed by our rules)\n",
    "4. We update our rules accordingly, and repeat until we're satisfied.\n",
    "    - Note that as new approaches are deployed, we have to identify and define new features to update our filter.\n",
    "\n",
    "<img src=\"image/traditional-programming.png\" alt=\"Traditional Programming\" width=\"600\"> \n",
    "\n",
    "<font size=4 color=B3A369><b>Spam Filters: Using Machine Learning</b></font>\n",
    "\n",
    "1. We need a reasonably large collection of emails that have been labeled as spam or not spam.\n",
    "    - The dataset may have defined characteristics (sender, message length, domain, etc.), or it may not, in which case we have to define our own.\n",
    "    - Additionally, we can always define additional fields from existing data through a process known as **feature engineering** (e.g., _x_ and _y_ coordinates might be better presented as polar coordinates for data centered around some location).\n",
    "2. We choose an algorithm that can consider the input characteristics and the categorization to determine which emails are spam and which are not.\n",
    "    - There are numerous existing algorithms (linear/logistic regression, neural networks, nearest neighbor, etc.) that can be modified, or a new algorithm can be defined (this is a very active research area after all!).\n",
    "3. We divide the dataset into training and test subsets, typically through some form of random selection.\n",
    "    - Different algorithms perform differently depending on the data, so we want to ascertain our model's efficacy before deploying it in the wild.\n",
    "    - Because of the underlying statistcs used in ML, it can often be helpful to explore resampling in an effort to assess the validity of our model.\n",
    "4. We tune our algorithm until we reach the desired level of accuracy, and then we deploy the model in the real world.\n",
    "    - Unlike the traditional method, machine learning has the ability to adapt to novel spam data - the model might need retraining, but we can in theory still use the same algorithm (this is what you're doing when you provide feedback on applications like Google Maps).\n",
    "\n",
    "<img src=\"image/machine_learning.png\" alt=\"Machine Learning\" width=\"600\"> \n",
    "\n",
    "<font size=5 color=B3A369><u><b>Using the Correct Tools...Correctly</b></u></font>\n",
    "\n",
    "There's often a difficult progression with ML projects from proof-of-concept to large-scale application, and a little foresight can reduce headaches significantly. Fortunately, framework such as TensorFlow and PyTorch significantly ease the transition from CPU to GPU, to the point where developing directly for GPU training is accessible. However, issues with scaling, either in terms of data or process distribution, can often manifest as one increases the scope of their project. Additionally, hardware-specific optimizations may be missed as code is migrated to new hardware, especially if outdated versions of computational libraries are used.\n",
    "\n",
    "Based on the hardware you've chosen to use, it's always worthwhile to explore the vendor's recommended settings. Since we'll be using Intel CPUs, we can take a look at their recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mDefault run\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 14:02:24.245839: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-10 14:02:27.413349: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50\n",
      "Batch size: 32\n",
      "Running warmup...\n",
      "Running benchmark...\n",
      "Iter #0: 26.8 img/sec per CPU\n",
      "Iter #1: 27.5 img/sec per CPU\n",
      "Img/sec per CPU: 27.1 +-0.7\n",
      "\n",
      "\u001b[1;34mImproved batch size\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 14:03:14.422991: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-10 14:03:17.647957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50\n",
      "Batch size: 192\n",
      "Running warmup...\n",
      "Running benchmark...\n",
      "Iter #0: 33.1 img/sec per CPU\n",
      "Iter #1: 33.4 img/sec per CPU\n",
      "Img/sec per CPU: 33.3 +-0.2\n",
      "\n",
      "\u001b[1;34mIntel Improved batch size\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 14:06:28.099363: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50\n",
      "Batch size: 192\n",
      "Running warmup...\n",
      "Running benchmark...\n",
      "Iter #0: 39.6 img/sec per CPU\n",
      "Iter #1: 40.8 img/sec per CPU\n",
      "Img/sec per CPU: 40.2 +-1.2\n",
      "\n",
      "\u001b[1;34mIntel Optimizations\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 14:09:08.159632: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0-23\n",
      "OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 24 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #192: KMP_AFFINITY: 2 sockets x 12 cores/socket x 1 thread/core (24 total cores)\n",
      "OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 1 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 2 maps to socket 0 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 3 maps to socket 0 core 3 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 4 maps to socket 0 core 4 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 5 maps to socket 0 core 5 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 6 maps to socket 0 core 8 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 7 maps to socket 0 core 10 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 8 maps to socket 0 core 11 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 9 maps to socket 0 core 12 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 10 maps to socket 0 core 13 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 11 maps to socket 0 core 14 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 12 maps to socket 1 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 13 maps to socket 1 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 14 maps to socket 1 core 3 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 15 maps to socket 1 core 4 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 16 maps to socket 1 core 5 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 17 maps to socket 1 core 6 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 18 maps to socket 1 core 8 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 19 maps to socket 1 core 9 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 20 maps to socket 1 core 10 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 21 maps to socket 1 core 11 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 22 maps to socket 1 core 12 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 23 maps to socket 1 core 13 thread 0 \n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31195 thread 0 bound to OS proc set 0\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31208 thread 1 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31209 thread 2 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31210 thread 3 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31211 thread 4 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31212 thread 5 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31213 thread 6 bound to OS proc set 6\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31214 thread 7 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31215 thread 8 bound to OS proc set 8\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31216 thread 9 bound to OS proc set 9\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31217 thread 10 bound to OS proc set 10\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31218 thread 11 bound to OS proc set 11\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31219 thread 12 bound to OS proc set 12\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31220 thread 13 bound to OS proc set 13\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31221 thread 14 bound to OS proc set 14\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31222 thread 15 bound to OS proc set 15\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31223 thread 16 bound to OS proc set 16\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31224 thread 17 bound to OS proc set 17\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31225 thread 18 bound to OS proc set 18\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31226 thread 19 bound to OS proc set 19\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31227 thread 20 bound to OS proc set 20\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31228 thread 21 bound to OS proc set 21\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31229 thread 22 bound to OS proc set 22\n",
      "OMP: Info #254: KMP_AFFINITY: pid 31160 tid 31230 thread 23 bound to OS proc set 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50\n",
      "Batch size: 192\n",
      "Running warmup...\n",
      "Running benchmark...\n",
      "Iter #0: 49.3 img/sec per CPU\n",
      "Iter #1: 49.4 img/sec per CPU\n",
      "Img/sec per CPU: 49.3 +-0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "source activate /storage/home/hpaceice1/shared-classes/envs/basic-tf\n",
    "echo -e \"\\033[1;34mDefault run\\033[m\"\n",
    "python ~/tf-bench/tensorflow2_synthetic_benchmark.py --num-iters 2\n",
    "echo -e \"\\n\\033[1;34mImproved batch size\\033[m\"\n",
    "python ~/tf-bench/tensorflow2_synthetic_benchmark.py --batch-size 192 --num-iters 2\n",
    "conda deactivate\n",
    "source activate apps-of-ml\n",
    "echo -e \"\\n\\033[1;34mIntel Improved batch size\\033[m\"\n",
    "python ~/tf-bench/tensorflow2_synthetic_benchmark.py --batch-size 192 --num-iters 2\n",
    "echo -e \"\\n\\033[1;34mIntel Optimizations\\033[m\"\n",
    "export KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
    "export TF_ENABLE_ONEDNN_OPTS=1\n",
    "export OMP_NUM_THREADS=$PBS_NP\n",
    "export KMP_BLOCKTIME=0\n",
    "python ~/tf-bench/tensorflow2_synthetic_benchmark.py --batch-size 192 --num-iters 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>Practical Example: ML in Medicine</b></u></font>\n",
    "\n",
    "When developing a machine learning workflow, it can be tempting to focus solely on the machine learning algorithm and model refinement. However, before that aspect can be considered, there are other challenges:\n",
    "- Where do we get the data?\n",
    "- Is the data formatted appropriately for the system?\n",
    "- What framework/hardware will be used?\n",
    "\n",
    "To explore these issues, we can use a standard training example from the community: automated breast cancer detection. As you may be aware, breast cancer is one of the most common cancers among women worldwide. Early diagnosis of breast cancer can greatly increase the outlook for patients, but accurate diagnosis can be a challenge as it requires expert analysis, and thus areas lacking in experts can be greatly affected.\n",
    "\n",
    "The Wisconsin breast cancer dataset consists of 30 parameters obtained via analysis of fine needle aspiration (FNA) biopsy of breast masses. This dataset has been previously studied in several papers, including [Breast Cancer Detection with Reduced Feature Set](https://www.hindawi.com/journals/cmmm/2015/265138/). Because each mass is labeled as benign or malignant, we can use the data to explore the application of machine learning techniques and gain insights into the viability of ML for real-world applications such as this.\n",
    "\n",
    "<font size=4 color=B3A369><b>Our Plan of Action</b></font>\n",
    "\n",
    "In this workshop, we will look at an example workflow on one of PACE's instructional clusters using CPUs for analysis. In short, we will use our labeled dataset of thirty features to train a classifier that will attempt to label new data as either benign or malignant. The steps we will take are as follows:\n",
    "1. Import the necessary libraries to explore/analyze our data and develop our model.\n",
    "2. Acquire our data and transform it to a useable form.\n",
    "3. Explore our data and garner any initial insights that might help us in our efforts.\n",
    "4. Prepare the data for training.\n",
    "5. Split the data into training and test subsets.\n",
    "6. Pick our ML algorithm and train our model.\n",
    "7. Test our model and explore the training process.\n",
    "\n",
    "<font size=5 color=B3A369><u><b>1. Import Libraries</b></u></font>\n",
    "\n",
    "There are numerous libraries that can be utilized in an ML project - we'll try to touch on several in this workshop to provide broader familiarity. (We actually ran the import call above to be more efficient in our use of time &#128513;).\n",
    "\n",
    "Sometimes, it is helpful to check versions of packages to verify capability/compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>2. Acquire/Transform Data</b></u></font>\n",
    "\n",
    "There are numerous sources for ML training sets, including directly from the Python libraries themselves. Picking one from the ML framework you're using has the advantage that it is usually formatted correctly, but since we want to explore the data transformation component of our workflow, we'll take our dataset from the SciKit-Learn datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # Loading the breast cancer from a standard datasource within SciKit\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data to get a better understanding of how it is formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the data uses human-readable characters, it's not formatted for easy reading by a human. We can manipulate it to change that!\n",
    "\n",
    "First, let's start by getting the names of the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this Python dictionary, we can focus on a single component of the dataset rather than dumping a block of information. For example, we can read the data description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to develop a classifier, ultimately we need to explore the labels, or targets, for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the target data is presented as a binary encoding (either 0 or 1). If we want to know which value maps to which label, we can use the \"target_names\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the array is 0-indexed, that means a value of '0' maps to 'malignant' and a value of '1' corresponds to 'benign'. \n",
    "\n",
    "Carrying on, the features of the set can be found by looking at the 'features_names' entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Pandas Dataframes</b></font>\n",
    "\n",
    "Since the data exhibits a fair amount of variety, we want to store it into an appropriate object. Pandas dataframes offer an excellent solution - they are data structures that provide labeled axes for heterogeneous data types, so they do exactly what we want! To convert our dataset to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.DataFrame(np.c_[cancer['data'],cancer['target']],columns=np.append(cancer['feature_names'],['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, TensorFlow does not allow spaces in feature names, so we'll have to fix that. This can be accomplished by looping over our dataset, replacing the spaces with a suitable character (e.g. an underscore), and updating our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_cancer.keys():\n",
    "    newkey = key.replace(\" \", \"_\")\n",
    "    df_cancer.rename(index=str,columns={key:newkey},inplace=True)\n",
    "print(df_cancer.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the nice functionality of a dataframe to look at the beginning of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or the end of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're feeling wild, we can even request more than 5 rows at a time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Feature Scaling</b></font>\n",
    "\n",
    "One thing that may immediately jump out is the variation in scale of the values for the different features. This can cause a few issues in our analysis if we're not careful:\n",
    "1. Some algorithms may not function when the scale of features is wildly different. For example, if a Euclidean distance is calculated, the larger feature may completely dominate the calculation.\n",
    "2. Gradient descent can converge more quickly if features are normalized, which can aid in training time.\n",
    "3. If regularization is used as part of the loss function, feature scaling is important to ensure that coefficients are penalized properly.\n",
    "\n",
    "Scikit-learn has built-in functionality that can perform our scaling and put all values in the range 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df_cancer.copy()\n",
    "df_scaled[['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
    "       'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "       'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "       'radius_error', 'texture_error', 'perimeter_error', 'area_error',\n",
    "       'smoothness_error', 'compactness_error', 'concavity_error',\n",
    "       'concave_points_error', 'symmetry_error', 'fractal_dimension_error',\n",
    "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
    "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "       'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']]=  scaler.fit_transform(df_scaled[['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
    "       'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "       'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "       'radius_error', 'texture_error', 'perimeter_error', 'area_error',\n",
    "       'smoothness_error', 'compactness_error', 'concavity_error',\n",
    "       'concave_points_error', 'symmetry_error', 'fractal_dimension_error',\n",
    "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
    "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "       'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']])\n",
    "print(df_scaled.head())\n",
    "print(df_scaled.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>3. Explore Data</b></u></font>\n",
    "\n",
    "Often it is assumed that with all the data, everything can be known. As it turns out, though, gathering the data isn't the only challenge of this approach; redundancy in the data and too many features can lead to inefficiencies in training. For example, in our dataset are there multiple descriptions of the same property that don't provide a additional insights? Or perhaps, are there any data points that seem purely superfluous?\n",
    "\n",
    "The challenge, of course, is how can we meaningfully pare down our data. Since we want to determine the target with our classifier, we can start by exploring how strongly correlated each feature is with the target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_scaled.corr()['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it helps if we organize our list, so let's start there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.corr()['target'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can give us insights into the impact of any one feature in terms of determining the target value, but lacks any information about data redundancies that may exist between different features. \n",
    "\n",
    "<font size=4 color=B3A369><b>Dataset Visualization</b></font>\n",
    "\n",
    "To explore the relationships between variables, we can utilize a correlation matrix heatmap, where the color indicates how strongly correlated each pair of features is. Values close to -1 show a strong negative correlation (one variable increases as the other decreases), while values close to +1 show a strong positive correlation (both increase or decrease together).\n",
    "\n",
    "While we can use other libraries to generate this heatmap, the Seaborn library provides a very simple, dataframe-compatible function to achieve our goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_scaled.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the default size can be difficult to view. Let's try to make that a little better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.heatmap(df_scaled.corr(),annot=True) # This is because of an issue in matplotlib. \n",
    "bottom, top = ax.get_ylim() \n",
    "ax.set_ylim(bottom+0.5, top-0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tempting to use all the features in a haphazard way. In our case, we see several parameters, such as the size of the cells to have multiple types of measurements. It is often advanatageous to try to minimize the number of features because of this and computational expense. \n",
    "\n",
    "Thinking about this in a mathematical sense, the features do not necessarily form a orthogonal basis set. This can lead to degenerate answers which may complicate the optimization process and either lead to a local extrema or failure of convergence. **This is in general terms of optimization, not strictly ML terms.** \n",
    "\n",
    "As related and practical matter, the large the feature set, the more expensive the calcuation is. By reducing the number of features, we try to increase the \"siginal-to-noise\" while decreasing the computational expense. \n",
    "\n",
    "In our case, we will use the mean parameters for a starting point because it reduces the number of features to 5. Inuitively, mean values tend to be a good choice for measuring trends.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_scaled, vars=['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Seaborn to color-code each datapoint based on the target value. This can help identify feature relationships that are the most indicative of a certain target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df_scaled,hue='target', vars=['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness'])\n",
    "# Below is to allow the legend to use words instead of numbers. \n",
    "handles = g._legend_data.values()\n",
    "labels = ['Malignant','Benign'] \n",
    "g._legend.remove()\n",
    "g.fig.legend(handles=handles,labels=labels, loc='center right',ncol=1)\n",
    "g.fig.subplots_adjust(top=0.92,bottom=0.08,right=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we might find it helpful to understand just how many values we have for each target label. A significant disparity can unintentionally bias our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_scaled['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>4. Prepare Data</b></u></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above, it seems fair to conclude that we have several values that are highly correlated, and that if we limit ourselves to just the mean values, we can reasonably represent the available data while maintaining efficiency (Disclaimer: this is just illustrative of a valid thought process, which may or may not actually be the optimal path forward with this dataset).\n",
    "\n",
    "In preparation of our application, we can define the features and labels to use in our ML classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness']\n",
    "labels=['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to shuffle our dataset. It's not uncommon to be provided a dataset that is sorted, which can bias results, so randomizing the order is usually a good first step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_data = df_scaled.reindex(np.random.permutation(df_scaled.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we didn't reindex our dataframe, we can see the original row labels and confirm that the order is different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>5. Split Data</b></u></font>\n",
    "\n",
    "Next, we need to define our training and test datasets. The trick here is to designate some fraction of our total dataset to be used for training, and then use the remainder to validate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = len(randomized_data)\n",
    "training_set_size_portion = 0.8\n",
    "training_set_size = int(total_records*training_set_size_portion)\n",
    "test_set_size = total_records - training_set_size\n",
    "print(total_records,training_set_size,test_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate our test by using the tail function on our randomized_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the testing features and labels\n",
    "testing_features = randomized_data.tail(test_set_size)[features].copy()\n",
    "testing_labels = randomized_data.tail(test_set_size)[labels].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can verify the content of the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and see that the indices for the targets match those of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build our training set from the other portion of randomized_data and confirm the same about its indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = randomized_data.head(training_set_size)[features].copy()\n",
    "training_labels = randomized_data.head(training_set_size)[labels].copy()\n",
    "print(training_features.head())\n",
    "print(training_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to define our feature columns for TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key) for key in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>6. Select ML Algorithm and Train</b></u></font>\n",
    "\n",
    "There are many models that can be used to attempt to solve the problem of classifying wheter the cancer is benign or malignant. In this example, we will use a neural network; which is a mathematical model that is inspired by how brains use.\n",
    "\n",
    "The strength of neural networks has been shown in the ability of these algorithms to excel in certain problems, especially classification. In the case of this problem, there is a deep pattern that is inside the set of data and the cancer outcome (otherwise, how would the physician's determination be better than a random determination). It seems like a fruitiful approach to develop neural network to classify each patient's data in terms of malignant or benign. \n",
    "\n",
    "<font size=4 color=B3A369><b>Neural Networks</b></font>\n",
    "\n",
    "Neural networks are a type of machine learning algorithm that are inspired by neurons in the human brain. Similar to neurons in the brains, neural networks are formed by interconnecting neurons that interact with each other. Each neuron takes input, does some simple alogrithm to it, and then passes an output to the next neuron.\n",
    "\n",
    "Let us look at a perceptron; that is, a single layer neural network. \n",
    "\n",
    "The *perceptron* is a mathematical function that takes a set of inputs, performs some operation, and outputs the result. In this case,\n",
    "$$ y = \\sum_{i} w_{i}x{i} + w_0,$$\n",
    "where $w_i$ is the weight of the perceptron and $w_0$ is the bias. Note that this is the form of a line (plane,hyperplane,...) The weights are used to determine the importance of the of that component and the bias shifts the activation function curve up and down. \n",
    "\n",
    "The results of the perceptron acting on the inputs, will be input into the activation function, which will determine how to classify the set. \n",
    "\n",
    "<font size=4 color=B3A369><b>Architecture of Neural Networks</b></font>\n",
    "\n",
    "A neural network consists of \n",
    "* An input layer \n",
    "* Any number of hidden layers (these are called hidden because the external observe does not see the output)\n",
    "* An output layer\n",
    "* A set of weights and bias between each layer $\\{w_i\\}, \\{b_i\\}$\n",
    "* An activation function for each layer, $\\sigma$\n",
    "\n",
    "<img src='image/neural_network_1.png'>\n",
    "\n",
    "<font size=4 color=B3A369><b>Training Process</b></font>\n",
    "\n",
    "Each iteration of the training process consists of the following steps:\n",
    "1. Calculating the predicted output $\\hat{y}$, known as _*Feedforward*_\n",
    "2. Updating the weights and biases, known as _*Backpropagation*_\n",
    "\n",
    "Schematicially, this can be illustated as \n",
    "<img src='image/nn_iteration.png'>\n",
    "\n",
    "<font size=3 color=B3A369><b>Feedforward</b></font>\n",
    "\n",
    "The forward motion is quite simply the calculation of the function in series, that is the the sum of the products of the weights and activations that lead to the neuron. Swe are moving forward in the network. \n",
    "\n",
    "The loss function comes into play at this point, since we must determine the \"goodness\" of our performance.\n",
    "There are many possibilities to use for the *loss* function, such as the familar *sum-of-squares error*\n",
    "$$ \\mathrm{loss} = \\sum_{i=1}^n (y-\\hat{y})^2$$\n",
    "\n",
    "<font size=3 color=B3A369><b>Backpropagation</b></font>\n",
    "\n",
    "As we measure the error of our prediction, we can now find a way to use the error to improve the network, if desired. This is termed *backpropagation*. We work away back to update the weights and biases for the neurons. \n",
    "\n",
    "Minimization of the error function is how this optimization. There are multiple methods to optimize these multiple dimension functions, a popular one method may be to use the derviative of the loss function to determine the path of greatest decrease as in *gradient descent*.\n",
    "\n",
    "<font size=4 color=B3A369><b>Hyperparameters</b></font>\n",
    "\n",
    "*Hyperparameters* are the *variables which determine the network structure* and *how the network is trained*. Examples that effect the *learning rate* are *epoch*, *batches*, and *iterations*. These are important parameters that are not learned by the network so they must be specified by the model designer. \n",
    "\n",
    "An *epoch* is when an entire training dataset is passed forward and backward through the network *once*. It is at the end of an epoch that parameters (weights and biases) have updated. In short (batch_size * number_iterations >= number_data)\n",
    "\n",
    "An *iteration* is the number of *batches* needed to complete one epoch.\n",
    "\n",
    "In some cases, the dataset will need to be divided into *batches* in order to fit everything in memory in order complete the calculations. Many ML frameworks natively support this with batches, but sometimes you may have to manually specify them.\n",
    "\n",
    "<font size=4 color=B3A369><b>Lets Try it Out</b></font>\n",
    "\n",
    "For our initial attempt, lets define a DNN Classifier with 3 layers, each with 10 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[10,10,10], n_classes=2,model_dir='tmp/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Train the Network</b></font>\n",
    "\n",
    "We define the training the input function now. \n",
    "\n",
    "The function that does this is \n",
    "\n",
    "`train_input_fn = tf.estimator.inputs.pandas_input_fn(x=training_features, y=training_labels['target'], num_epochs=15,shuffle=True)`\n",
    "\n",
    "In this case, we will pass through the data set 15 times, updating the weight and biases based on the loss.\n",
    "<https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn> for complete documentation of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn =  tf.compat.v1.estimator.inputs.pandas_input_fn(x=training_features,y=training_labels['target'],num_epochs=15,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(training_features['mean_radius']), type(training_labels['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note** If you are reruning the calculation, it may be necessary to clean out the tmp directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.train(input_fn=train_input_fn,steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Test the Model</b></font>\n",
    "\n",
    "Now that we've trained our network, we can use our test dataset (the other 20% that we didn't use to train the model) to validate its performance. Generally speaking, we are most interested in the accuracy, but you may be interested in analyzing the loss function to see how quickly we converge to an appropriate solution, or perhaps the variability in the accuracy due to statistical fluctuations.\n",
    "\n",
    "Let's see how it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=testing_features,y=testing_labels['target'],num_epochs=15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_v2.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>7. Improve the Accuracy</b></u></font>\n",
    "\n",
    "Since the accuracy is not very high, let us start to try to improve the accuracy.\n",
    "There are a number of ways to increase accuracy:\n",
    "\n",
    "- Increase hidden layers\n",
    "- Change activiation function\n",
    "- Change activation function in output layer\n",
    "- Increase number of neurons\n",
    "- Weight initialization\n",
    "- More data\n",
    "- Normalization/scaling data\n",
    "- Change learning algorith parameters\n",
    "- Use a different model\n",
    "\n",
    "\n",
    "Let's try to improve the accuracy by using a linear classifier instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_v2 = tf.estimator.LinearClassifier(feature_columns=feature_columns,n_classes=2,model_dir='tmp/model_2')\n",
    "classifier_v2.train(input_fn=train_input_fn,steps=2000)\n",
    "classifier_v2.evaluate(input_fn=test_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-apps-of-ml]",
   "language": "python",
   "name": "conda-env-.conda-apps-of-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
